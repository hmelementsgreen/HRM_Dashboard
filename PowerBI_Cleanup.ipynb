{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89fc30ab-08a0-42c9-8b86-bab13bfef935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HarshMalhotra\\AppData\\Local\\Temp\\ipykernel_23608\\4112044405.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[text_cols] = df[text_cols].applymap(fix_text)\n",
      "C:\\Users\\HarshMalhotra\\AppData\\Local\\Temp\\ipykernel_23608\\4112044405.py:56: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Absence_PowerBI_Ready.csv'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"AbsenseReport_Cleaned_Final.csv\")\n",
    "\n",
    "# 1. Standardise column names\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")\n",
    "\n",
    "# 2. Fix encoding / special characters\n",
    "def fix_text(x):\n",
    "    if isinstance(x, str):\n",
    "        return unicodedata.normalize(\"NFKC\", x)\n",
    "    return x\n",
    "\n",
    "text_cols = df.select_dtypes(include=\"object\").columns\n",
    "df[text_cols] = df[text_cols].applymap(fix_text)\n",
    "\n",
    "# 3. Parse dates (adjust column names if needed)\n",
    "date_cols = [c for c in df.columns if \"date\" in c]\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "# 4. Time features for Power BI\n",
    "if \"start_date\" in df.columns:\n",
    "    df[\"year\"] = df[\"start_date\"].dt.year\n",
    "    df[\"month\"] = df[\"start_date\"].dt.month\n",
    "    df[\"month_year\"] = df[\"start_date\"].dt.strftime(\"%Y-%m\")\n",
    "\n",
    "# 5. Absence category mapping\n",
    "def map_absence(x):\n",
    "    x = str(x).lower()\n",
    "    if \"annual\" in x:\n",
    "        return \"Annual\"\n",
    "    if any(k in x for k in [\"sick\", \"medical\", \"dental\", \"maternity\"]):\n",
    "        return \"Medical\"\n",
    "    if any(k in x for k in [\"wfh\", \"home\"]):\n",
    "        return \"Work From Home\"\n",
    "    if \"travel\" in x:\n",
    "        return \"Travel\"\n",
    "    return \"Other\"\n",
    "\n",
    "if \"absence_type\" in df.columns:\n",
    "    df[\"absence_category\"] = df[\"absence_type\"].apply(map_absence)\n",
    "\n",
    "# 6. Numeric cleanup\n",
    "if \"absence_days\" in df.columns:\n",
    "    df[\"absence_days\"] = pd.to_numeric(df[\"absence_days\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# 7. Final trim\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# 8. Export Power BI–ready file\n",
    "output_path = \"Absence_PowerBI_Ready.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f12f3b-a0e7-47f9-8510-16526248ad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tzdata in c:\\users\\harshmalhotra\\anaconda3\\lib\\site-packages (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tzdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "668e0d11-b068-4dba-82d5-0978737f34f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Power BI-ready file to: Absence_PowerBI_Ready.csv\n",
      "Columns: ['first_name', 'last_name', 'team_names', 'leave_entitlement', 'entitlement_unit', 'absence_type', 'absence_duration_total_in_days', 'absence_duration_for_period_in_days', 'absence_description', 'absence_start_date', 'absence_end_date', 'organisation', 'suborganisation', 'absence_category']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HarshMalhotra\\AppData\\Local\\Temp\\ipykernel_23608\\742854540.py:104: UserWarning: Parsing dates in %m/%d/%Y %H:%M format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  parsed = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HarshMalhotra\\AppData\\Local\\Temp\\ipykernel_23608\\742854540.py:104: UserWarning: Parsing dates in %m/%d/%Y %H:%M format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  parsed = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "INPUT_CSV  = \"AbsenseReport_Cleaned_Final.csv\"\n",
    "OUTPUT_CSV = \"Absence_PowerBI_Ready.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def clean_colname(c: str) -> str:\n",
    "    c = str(c).strip().lower()\n",
    "    c = re.sub(r\"[^\\w\\s]\", \"\", c)          # remove punctuation\n",
    "    c = re.sub(r\"\\s+\", \"_\", c)             # spaces -> underscore\n",
    "    c = re.sub(r\"_+\", \"_\", c).strip(\"_\")   # collapse underscores\n",
    "    return c\n",
    "\n",
    "def fix_mojibake(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Fix common UTF-8-in-Latin1 mojibake like:\n",
    "    'BarÄ±ÅŸ AkyÃ¼z' -> 'Barış Akyüz'\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    s = s.strip()\n",
    "    if not s:\n",
    "        return s\n",
    "\n",
    "    # First: normalize unicode form\n",
    "    s_norm = unicodedata.normalize(\"NFKC\", s)\n",
    "\n",
    "    # Try: latin1 -> utf8 decode (common corruption)\n",
    "    try:\n",
    "        repaired = s_norm.encode(\"latin1\", errors=\"strict\").decode(\"utf-8\", errors=\"strict\")\n",
    "        # If repair looks better (contains more non-ASCII letters in a reasonable way), keep it\n",
    "        # (Very simple heuristic: repaired has fewer 'Ã'/'Å' artifacts)\n",
    "        if (\"Ã\" in s_norm or \"Å\" in s_norm or \"Ä\" in s_norm) and not (\"Ã\" in repaired or \"Å\" in repaired or \"Ä\" in repaired):\n",
    "            s_norm = repaired\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return unicodedata.normalize(\"NFKC\", s_norm).strip()\n",
    "\n",
    "def map_absence_category(x: str) -> str:\n",
    "    x = str(x).lower().strip()\n",
    "\n",
    "    # annual\n",
    "    if \"annual\" in x:\n",
    "        return \"Annual\"\n",
    "\n",
    "    # medical bucket\n",
    "    if any(k in x for k in [\"sick\", \"sickness\", \"medical\", \"dental\", \"maternity\", \"bereave\", \"compassion\", \"appointment\"]):\n",
    "        return \"Medical\"\n",
    "\n",
    "    # WFH bucket (also catches \"work from home\", \"home working\" etc.)\n",
    "    if any(k in x for k in [\"wfh\", \"work from home\", \"working from home\", \"home working\", \"remote\"]):\n",
    "        return \"Work From Home\"\n",
    "\n",
    "    # travel bucket\n",
    "    if \"travel\" in x:\n",
    "        return \"Travel\"\n",
    "\n",
    "    return \"Other\"\n",
    "\n",
    "def robust_to_date(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    \n",
    "    Parse to pandas datetime then drop time (Option 1: keep as date type).\n",
    "    Uses dayfirst=True to match UK dd/mm formats.\n",
    "    \"\"\"\n",
    "    dt = pd.to_datetime(series, errors=\"coerce\", dayfirst=True)\n",
    "    return dt.dt.date  # <- removes time; stays date-like for Power BI\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load\n",
    "# -----------------------------\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Standardise column names\n",
    "# -----------------------------\n",
    "df.columns = [clean_colname(c) for c in df.columns]\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Fix text columns (trim + encoding repair)\n",
    "# -----------------------------\n",
    "obj_cols = df.select_dtypes(include=\"object\").columns\n",
    "for c in obj_cols:\n",
    "    df[c] = df[c].map(fix_mojibake)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Identify likely date columns and convert to DATE-ONLY (Option 1)\n",
    "# -----------------------------\n",
    "# Common date column names we might see\n",
    "candidate_date_cols = []\n",
    "for c in df.columns:\n",
    "    if any(tok in c for tok in [\"date\", \"start\", \"end\", \"from\", \"to\"]):\n",
    "        # avoid false positives like \"updated_by\" etc.\n",
    "        if \"name\" not in c and \"type\" not in c and \"reason\" not in c:\n",
    "            candidate_date_cols.append(c)\n",
    "\n",
    "# Apply conversion to date-only for columns that actually parse like dates\n",
    "for c in candidate_date_cols:\n",
    "    parsed = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=True)\n",
    "    if parsed.notna().mean() > 0.6:  # only convert if most values look like dates\n",
    "        df[c] = parsed.dt.date\n",
    "\n",
    "# Prefer a primary \"start_date\" for time slicing; create it if needed\n",
    "# Adjust these aliases based on your real columns:\n",
    "start_aliases = [\"start_date\", \"start\", \"from_date\", \"date_from\", \"absence_start\", \"startdate\"]\n",
    "end_aliases   = [\"end_date\", \"end\", \"to_date\", \"date_to\", \"absence_end\", \"enddate\"]\n",
    "\n",
    "def first_existing(cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "start_col = first_existing(start_aliases)\n",
    "end_col   = first_existing(end_aliases)\n",
    "\n",
    "# If you have a single date column (e.g., \"date\"), treat it as start_date\n",
    "if start_col is None and \"date\" in df.columns:\n",
    "    start_col = \"date\"\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Add Power BI-friendly time features\n",
    "# -----------------------------\n",
    "if start_col is not None:\n",
    "    # Convert the date-only back to datetime temporarily for easy feature extraction\n",
    "    start_dt = pd.to_datetime(df[start_col], errors=\"coerce\")\n",
    "    df[\"year\"] = start_dt.dt.year\n",
    "    df[\"month\"] = start_dt.dt.month\n",
    "    df[\"month_name\"] = start_dt.dt.strftime(\"%b\")         # Jan, Feb...\n",
    "    df[\"month_year\"] = start_dt.dt.strftime(\"%Y-%m\")      # 2026-01 (sortable)\n",
    "    df[\"week_start\"] = (start_dt - pd.to_timedelta(start_dt.dt.weekday, unit=\"D\")).dt.date  # Monday week start\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Create a clean absence_category\n",
    "# -----------------------------\n",
    "# Try to find the absence type column\n",
    "type_aliases = [\"absence_type\", \"type\", \"absence\", \"leave_type\", \"category\", \"reason\"]\n",
    "type_col = first_existing(type_aliases)\n",
    "\n",
    "if type_col is not None:\n",
    "    df[\"absence_category\"] = df[type_col].map(map_absence_category)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Numeric cleanup (days/hours)\n",
    "# -----------------------------\n",
    "numeric_aliases = [\"absence_days\", \"days\", \"duration_days\", \"total_days\", \"days_absent\", \"duration\"]\n",
    "num_col = first_existing(numeric_aliases)\n",
    "if num_col is not None:\n",
    "    df[num_col] = pd.to_numeric(df[num_col], errors=\"coerce\")\n",
    "\n",
    "# If there is no numeric duration, try deriving it from start/end (inclusive)\n",
    "if num_col is None and start_col is not None and end_col is not None:\n",
    "    s = pd.to_datetime(df[start_col], errors=\"coerce\")\n",
    "    e = pd.to_datetime(df[end_col], errors=\"coerce\")\n",
    "    df[\"absence_days\"] = (e - s).dt.days + 1\n",
    "    df[\"absence_days\"] = df[\"absence_days\"].where(df[\"absence_days\"].notna(), 0).clip(lower=0)\n",
    "\n",
    "# Fill numeric NaNs to 0 only where that makes sense (duration measures)\n",
    "for c in [\"absence_days\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Final string trim (again, safe)\n",
    "# -----------------------------\n",
    "obj_cols = df.select_dtypes(include=\"object\").columns\n",
    "for c in obj_cols:\n",
    "    df[c] = df[c].astype(str).str.strip().replace({\"nan\": None, \"None\": None, \"\": None})\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Export Power BI-ready CSV\n",
    "# -----------------------------\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(\"Saved Power BI-ready file to:\", OUTPUT_CSV)\n",
    "print(\"Columns:\", list(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbacb229-e68b-42c9-98ef-060ddfa3f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "                     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
