{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10763186-d8a4-4eda-a803-0f56925412d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First name</th>\n",
       "      <th>Last name</th>\n",
       "      <th>Team names</th>\n",
       "      <th>Leave entitlement</th>\n",
       "      <th>Entitlement unit</th>\n",
       "      <th>Absence type</th>\n",
       "      <th>Absence duration total in days</th>\n",
       "      <th>Absence duration for period in days</th>\n",
       "      <th>Absence description</th>\n",
       "      <th>Absence start date</th>\n",
       "      <th>Absence end date</th>\n",
       "      <th>Status reason</th>\n",
       "      <th>Absence status</th>\n",
       "      <th>Is ongoing</th>\n",
       "      <th>Fit note required</th>\n",
       "      <th>Estimated return date</th>\n",
       "      <th>Sickness start date type</th>\n",
       "      <th>Sickness end date type</th>\n",
       "      <th>Toil notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>days</td>\n",
       "      <td>Other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pre-agreed WFH days</td>\n",
       "      <td>7/18/2025 0:00</td>\n",
       "      <td>7/23/2025 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>days</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WFH</td>\n",
       "      <td>9/12/2025 0:00</td>\n",
       "      <td>9/12/2025 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>days</td>\n",
       "      <td>Sickness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/10/2025 0:00</td>\n",
       "      <td>4/10/2025 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>days</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WFH</td>\n",
       "      <td>11/21/2025 0:00</td>\n",
       "      <td>11/21/2025 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>days</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/15/2025 0:00</td>\n",
       "      <td>1/15/2025 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First name Last name Team names  Leave entitlement Entitlement unit  \\\n",
       "0   Stefanie   Lenehan         HR               20.0             days   \n",
       "1   Stefanie   Lenehan         HR               20.0             days   \n",
       "2   Stefanie   Lenehan         HR               20.0             days   \n",
       "3   Stefanie   Lenehan         HR               20.0             days   \n",
       "4   Stefanie   Lenehan         HR               20.0             days   \n",
       "\n",
       "  Absence type  Absence duration total in days  \\\n",
       "0        Other                             4.0   \n",
       "1        Other                             1.0   \n",
       "2     Sickness                             1.0   \n",
       "3        Other                             1.0   \n",
       "4        Other                             1.0   \n",
       "\n",
       "   Absence duration for period in days   Absence description  \\\n",
       "0                                  4.0  Pre-agreed WFH days    \n",
       "1                                  1.0                   WFH   \n",
       "2                                  1.0                   NaN   \n",
       "3                                  1.0                   WFH   \n",
       "4                                  1.0                   NaN   \n",
       "\n",
       "  Absence start date Absence end date Status reason Absence status Is ongoing  \\\n",
       "0     7/18/2025 0:00   7/23/2025 0:00           NaN       APPROVED      False   \n",
       "1     9/12/2025 0:00   9/12/2025 0:00           NaN       APPROVED      False   \n",
       "2     4/10/2025 0:00   4/10/2025 0:00           NaN            NaN      False   \n",
       "3    11/21/2025 0:00  11/21/2025 0:00           NaN       APPROVED      False   \n",
       "4     1/15/2025 0:00   1/15/2025 0:00           NaN       APPROVED      False   \n",
       "\n",
       "  Fit note required  Estimated return date Sickness start date type  \\\n",
       "0               NaN                    NaN                      NaN   \n",
       "1               NaN                    NaN                      NaN   \n",
       "2             False                    NaN                  UNKNOWN   \n",
       "3               NaN                    NaN                      NaN   \n",
       "4               NaN                    NaN                      NaN   \n",
       "\n",
       "  Sickness end date type  Toil notes  \n",
       "0                    NaN         NaN  \n",
       "1                    NaN         NaN  \n",
       "2                UNKNOWN         NaN  \n",
       "3                    NaN         NaN  \n",
       "4                    NaN         NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv(\"AbsenseReportRaw.csv\")\n",
    "\n",
    "# Preview the data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c7015d0-012a-4ded-99ed-8d8f5e0efdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['First name', 'Last name', 'Team names', 'Leave entitlement',\n",
       "       'Absence type', 'Absence duration total in days',\n",
       "       'Absence duration for period in days', 'Absence description',\n",
       "       'Absence start date', 'Absence end date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to remove\n",
    "cols_to_remove = [\n",
    "    \"Status reason\",\n",
    "    \"Absence status\",\n",
    "    \"Is ongoing\",\n",
    "    \"Fit note required\",\n",
    "    \"Estimated return date\",\n",
    "    'Entitlement unit',\n",
    "    \"Sickness start date type\",\n",
    "    \"Sickness end date type\",\n",
    "    \"Toil notes\"\n",
    "]\n",
    "\n",
    "# Drop columns\n",
    "df = df.drop(columns=cols_to_remove, errors=\"ignore\")\n",
    "\n",
    "# Check remaining columns\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ca32b59-b46c-4abc-9d4d-1e0d8d310487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First name</th>\n",
       "      <th>Last name</th>\n",
       "      <th>Team names</th>\n",
       "      <th>Leave entitlement</th>\n",
       "      <th>Absence type</th>\n",
       "      <th>Absence duration total in days</th>\n",
       "      <th>Absence duration for period in days</th>\n",
       "      <th>Absence description</th>\n",
       "      <th>Absence start date</th>\n",
       "      <th>Absence end date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pre-agreed WFH days</td>\n",
       "      <td>7/18/2025 0:00</td>\n",
       "      <td>7/23/2025 0:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WFH</td>\n",
       "      <td>9/12/2025 0:00</td>\n",
       "      <td>9/12/2025 0:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Sickness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/10/2025 0:00</td>\n",
       "      <td>4/10/2025 0:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WFH</td>\n",
       "      <td>11/21/2025 0:00</td>\n",
       "      <td>11/21/2025 0:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/15/2025 0:00</td>\n",
       "      <td>1/15/2025 0:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First name Last name Team names  Leave entitlement Absence type  \\\n",
       "0   Stefanie   Lenehan         HR               20.0        Other   \n",
       "1   Stefanie   Lenehan         HR               20.0        Other   \n",
       "2   Stefanie   Lenehan         HR               20.0     Sickness   \n",
       "3   Stefanie   Lenehan         HR               20.0        Other   \n",
       "4   Stefanie   Lenehan         HR               20.0        Other   \n",
       "\n",
       "   Absence duration total in days  Absence duration for period in days  \\\n",
       "0                             4.0                                  4.0   \n",
       "1                             1.0                                  1.0   \n",
       "2                             1.0                                  1.0   \n",
       "3                             1.0                                  1.0   \n",
       "4                             1.0                                  1.0   \n",
       "\n",
       "    Absence description Absence start date Absence end date  \n",
       "0  Pre-agreed WFH days      7/18/2025 0:00   7/23/2025 0:00  \n",
       "1                   WFH     9/12/2025 0:00   9/12/2025 0:00  \n",
       "2                   NaN     4/10/2025 0:00   4/10/2025 0:00  \n",
       "3                   WFH    11/21/2025 0:00  11/21/2025 0:00  \n",
       "4                   NaN     1/15/2025 0:00   1/15/2025 0:00  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95a6cba4-7296-43f4-a371-cfc3bb765912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HR', 'Operations', 'EG Finance', 'Engineering', 'UK BDM',\n",
       "       'Investment', 'Executive', 'DE BDM', 'Group Legal', 'Agri',\n",
       "       'UG Business Support ', 'Group Finance', 'Property', nan,\n",
       "       'AG Legal'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of unique team names\n",
    "df[\"Team names\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f8fdc0df-8d42-4396-a4c5-24c650e47b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First name</th>\n",
       "      <th>Last name</th>\n",
       "      <th>Team names</th>\n",
       "      <th>Leave entitlement</th>\n",
       "      <th>Absence type</th>\n",
       "      <th>Absence duration total in days</th>\n",
       "      <th>Absence duration for period in days</th>\n",
       "      <th>Absence description</th>\n",
       "      <th>Absence start date</th>\n",
       "      <th>Absence end date</th>\n",
       "      <th>Organisation</th>\n",
       "      <th>Suborganisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pre-agreed WFH days</td>\n",
       "      <td>7/18/2025 0:00</td>\n",
       "      <td>7/23/2025 0:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WFH</td>\n",
       "      <td>9/12/2025 0:00</td>\n",
       "      <td>9/12/2025 0:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Sickness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/10/2025 0:00</td>\n",
       "      <td>4/10/2025 0:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WFH</td>\n",
       "      <td>11/21/2025 0:00</td>\n",
       "      <td>11/21/2025 0:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/15/2025 0:00</td>\n",
       "      <td>1/15/2025 0:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First name Last name Team names  Leave entitlement Absence type  \\\n",
       "0   Stefanie   Lenehan         HR               20.0        Other   \n",
       "1   Stefanie   Lenehan         HR               20.0        Other   \n",
       "2   Stefanie   Lenehan         HR               20.0     Sickness   \n",
       "3   Stefanie   Lenehan         HR               20.0        Other   \n",
       "4   Stefanie   Lenehan         HR               20.0        Other   \n",
       "\n",
       "   Absence duration total in days  Absence duration for period in days  \\\n",
       "0                             4.0                                  4.0   \n",
       "1                             1.0                                  1.0   \n",
       "2                             1.0                                  1.0   \n",
       "3                             1.0                                  1.0   \n",
       "4                             1.0                                  1.0   \n",
       "\n",
       "    Absence description Absence start date Absence end date Organisation  \\\n",
       "0  Pre-agreed WFH days      7/18/2025 0:00   7/23/2025 0:00         None   \n",
       "1                   WFH     9/12/2025 0:00   9/12/2025 0:00         None   \n",
       "2                   NaN     4/10/2025 0:00   4/10/2025 0:00         None   \n",
       "3                   WFH    11/21/2025 0:00  11/21/2025 0:00         None   \n",
       "4                   NaN     1/15/2025 0:00   1/15/2025 0:00         None   \n",
       "\n",
       "  Suborganisation  \n",
       "0            None  \n",
       "1            None  \n",
       "2            None  \n",
       "3            None  \n",
       "4            None  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add new columns with empty values\n",
    "df[\"Organisation\"] = None\n",
    "df[\"Suborganisation\"] = None\n",
    "\n",
    "# Verify\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7c7434a3-42ea-4fb1-9687-ee2126b51129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team names</th>\n",
       "      <th>Organisation</th>\n",
       "      <th>Suborganisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HR</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Operations</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>EG Finance</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>UK BDM</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>Investment</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>DE BDM</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team names Organisation Suborganisation\n",
       "0             HR           AG              EG\n",
       "49    Operations           AG              EG\n",
       "120   EG Finance           AG              EG\n",
       "359  Engineering           AG              EG\n",
       "388       UK BDM           AG              EG\n",
       "575   Investment           AG              EG\n",
       "663       DE BDM           AG              EG"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teams to be mapped\n",
    "teams_eg = [\n",
    "    \"HR\",\n",
    "    \"UK BDM\",\n",
    "    \"DE BDM\",\n",
    "    \"Engineering\",\n",
    "    \"Operations\",\n",
    "    \"Investment\",\n",
    "    \"Investments\",\n",
    "    'EG Finance'# kept for safety in case of naming variation\n",
    "]\n",
    "\n",
    "# Assign organisation and suborganisation\n",
    "df.loc[df[\"Team names\"].isin(teams_eg), \"Organisation\"] = \"AG\"\n",
    "df.loc[df[\"Team names\"].isin(teams_eg), \"Suborganisation\"] = \"EG\"\n",
    "\n",
    "# Quick validation\n",
    "df[df[\"Team names\"].isin(teams_eg)][\n",
    "    [\"Team names\", \"Organisation\", \"Suborganisation\"]\n",
    "].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "80602a70-b99c-4df0-8aa6-7489585c8642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First name</th>\n",
       "      <th>Last name</th>\n",
       "      <th>Team names</th>\n",
       "      <th>Leave entitlement</th>\n",
       "      <th>Absence type</th>\n",
       "      <th>Absence duration total in days</th>\n",
       "      <th>Absence duration for period in days</th>\n",
       "      <th>Absence description</th>\n",
       "      <th>Absence start date</th>\n",
       "      <th>Absence end date</th>\n",
       "      <th>Organisation</th>\n",
       "      <th>Suborganisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pre-agreed WFH days</td>\n",
       "      <td>7/18/2025 0:00</td>\n",
       "      <td>7/23/2025 0:00</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WFH</td>\n",
       "      <td>9/12/2025 0:00</td>\n",
       "      <td>9/12/2025 0:00</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Sickness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/10/2025 0:00</td>\n",
       "      <td>4/10/2025 0:00</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WFH</td>\n",
       "      <td>11/21/2025 0:00</td>\n",
       "      <td>11/21/2025 0:00</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/15/2025 0:00</td>\n",
       "      <td>1/15/2025 0:00</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First name Last name Team names  Leave entitlement Absence type  \\\n",
       "0   Stefanie   Lenehan         HR               20.0        Other   \n",
       "1   Stefanie   Lenehan         HR               20.0        Other   \n",
       "2   Stefanie   Lenehan         HR               20.0     Sickness   \n",
       "3   Stefanie   Lenehan         HR               20.0        Other   \n",
       "4   Stefanie   Lenehan         HR               20.0        Other   \n",
       "\n",
       "   Absence duration total in days  Absence duration for period in days  \\\n",
       "0                             4.0                                  4.0   \n",
       "1                             1.0                                  1.0   \n",
       "2                             1.0                                  1.0   \n",
       "3                             1.0                                  1.0   \n",
       "4                             1.0                                  1.0   \n",
       "\n",
       "    Absence description Absence start date Absence end date Organisation  \\\n",
       "0  Pre-agreed WFH days      7/18/2025 0:00   7/23/2025 0:00           AG   \n",
       "1                   WFH     9/12/2025 0:00   9/12/2025 0:00           AG   \n",
       "2                   NaN     4/10/2025 0:00   4/10/2025 0:00           AG   \n",
       "3                   WFH    11/21/2025 0:00  11/21/2025 0:00           AG   \n",
       "4                   NaN     1/15/2025 0:00   1/15/2025 0:00           AG   \n",
       "\n",
       "  Suborganisation  \n",
       "0              EG  \n",
       "1              EG  \n",
       "2              EG  \n",
       "3              EG  \n",
       "4              EG  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff119aae-5e1c-4125-a1c3-749d2173cb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team names</th>\n",
       "      <th>Organisation</th>\n",
       "      <th>Suborganisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>Group Legal</td>\n",
       "      <td>AG</td>\n",
       "      <td>AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>Agri</td>\n",
       "      <td>AG</td>\n",
       "      <td>AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>AG Legal</td>\n",
       "      <td>AG</td>\n",
       "      <td>AG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Team names Organisation Suborganisation\n",
       "834   Group Legal           AG              AG\n",
       "856          Agri           AG              AG\n",
       "1669     AG Legal           AG              AG"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teams where both Organisation and Suborganisation should be AG\n",
    "teams_ag = [\n",
    "    \"Agri\",\n",
    "    \"AG Legal\",\n",
    "    \"Group Legal\"\n",
    "]\n",
    "\n",
    "# Assign Organisation and Suborganisation\n",
    "df.loc[df[\"Team names\"].isin(teams_ag), \"Organisation\"] = \"AG\"\n",
    "df.loc[df[\"Team names\"].isin(teams_ag), \"Suborganisation\"] = \"AG\"\n",
    "\n",
    "# Validate mapping\n",
    "df[df[\"Team names\"].isin(teams_ag)][\n",
    "    [\"Team names\", \"Organisation\", \"Suborganisation\"]\n",
    "].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d8111000-284b-491d-9c39-8721b1c8d000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Executive', 'UG Business Support ', 'Group Finance', 'Property'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teams where Organisation or Suborganisation is still missing\n",
    "unassigned_teams = (\n",
    "    df.loc[\n",
    "        df[\"Organisation\"].isna() | df[\"Suborganisation\"].isna(),\n",
    "        \"Team names\"\n",
    "    ]\n",
    "    .dropna()\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "unassigned_teams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b4f732f-3eff-4528-97a9-a39f92f9365b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team names</th>\n",
       "      <th>Organisation</th>\n",
       "      <th>Suborganisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>Executive</td>\n",
       "      <td>UG</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>UG Business Support</td>\n",
       "      <td>UG</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Group Finance</td>\n",
       "      <td>UG</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>Property</td>\n",
       "      <td>UG</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Team names Organisation Suborganisation\n",
       "601             Executive           UG              UG\n",
       "870  UG Business Support            UG              UG\n",
       "889         Group Finance           UG              UG\n",
       "910              Property           UG              UG"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teams to be assigned to UG / UG\n",
    "teams_ug = [\n",
    "    \"Executive\",\n",
    "    \"UG Business Support \",\n",
    "    \"Group Finance\",\n",
    "    \"Property\"\n",
    "]\n",
    "\n",
    "# Assign Organisation and Suborganisation\n",
    "df.loc[df[\"Team names\"].isin(teams_ug), \"Organisation\"] = \"UG\"\n",
    "df.loc[df[\"Team names\"].isin(teams_ug), \"Suborganisation\"] = \"UG\"\n",
    "\n",
    "# Validate mapping\n",
    "df[df[\"Team names\"].isin(teams_ug)][\n",
    "    [\"Team names\", \"Organisation\", \"Suborganisation\"]\n",
    "].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d14da33b-e96a-4f6a-9289-866dcbd54959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teams where Organisation or Suborganisation is still missing\n",
    "unassigned_teams = (\n",
    "    df.loc[\n",
    "        df[\"Organisation\"].isna() | df[\"Suborganisation\"].isna(),\n",
    "        \"Team names\"\n",
    "    ]\n",
    "    .dropna()\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "unassigned_teams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "610a087d-18bf-4ae5-9814-7b3e9c25c98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>WFH mentioned in description</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Absence type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual leave</th>\n",
       "      <td>480</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bereavement leave</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Compassionate leave</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dental appointment</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maternity leave</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medical appointment</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missing</th>\n",
       "      <td>748</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>152</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sickness</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training / events</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "WFH mentioned in description  False  True \n",
       "Absence type                              \n",
       "Annual leave                    480      3\n",
       "Bereavement leave                 1      0\n",
       "Compassionate leave               1      0\n",
       "Dental appointment                3      0\n",
       "Maternity leave                   1      0\n",
       "Medical appointment              15      1\n",
       "Missing                         748      0\n",
       "Other                           152    242\n",
       "Sickness                         22      0\n",
       "Training / events                 1      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absence type</th>\n",
       "      <th>Absence description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>Pre-agreed WFH days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other</td>\n",
       "      <td>WFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Other</td>\n",
       "      <td>WFH as still feeling unwell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Other</td>\n",
       "      <td>wfh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Other</td>\n",
       "      <td>WFH - dentist appointment near my house in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Other</td>\n",
       "      <td>WFH as feeling unwell - will see how I am tomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Other</td>\n",
       "      <td>Pre- agreed WFH days as I'm going back to my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Other</td>\n",
       "      <td>WFH - not feeling well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Other</td>\n",
       "      <td>Working from home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Other</td>\n",
       "      <td>WFH (medical appointment)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Other</td>\n",
       "      <td>Working remotely from Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Other</td>\n",
       "      <td>Working from Home\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Other</td>\n",
       "      <td>Working From Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Other</td>\n",
       "      <td>Medical appointment in the morning then workin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Other</td>\n",
       "      <td>WFH - medical appointment in the morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Other</td>\n",
       "      <td>Work from home in the AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Other</td>\n",
       "      <td>WFH - India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Annual leave</td>\n",
       "      <td>WFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Other</td>\n",
       "      <td>WFH due to flu symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Other</td>\n",
       "      <td>WFH due to ongoing illness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Other</td>\n",
       "      <td>As per Teams message (wfh)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Medical appointment</td>\n",
       "      <td>Working from Home\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Other</td>\n",
       "      <td>wfh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Other</td>\n",
       "      <td>WFH day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>Other</td>\n",
       "      <td>wfh - need to be home due to contractors comin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Other</td>\n",
       "      <td>wfh - due to feeling ill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>Other</td>\n",
       "      <td>WFH- Boiler Safety certificate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>Other</td>\n",
       "      <td>DR- WFH post-surgery as discussed with ES and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Absence type                                Absence description\n",
       "0                  Other                               Pre-agreed WFH days \n",
       "1                  Other                                                WFH\n",
       "13                 Other                        WFH as still feeling unwell\n",
       "25                 Other                                               wfh \n",
       "28                 Other  WFH - dentist appointment near my house in the...\n",
       "40                 Other  WFH as feeling unwell - will see how I am tomo...\n",
       "42                 Other  Pre- agreed WFH days as I'm going back to my f...\n",
       "43                 Other                            WFH - not feeling well \n",
       "64                 Other                                  Working from home\n",
       "76                 Other                          WFH (medical appointment)\n",
       "78                 Other                        Working remotely from Italy\n",
       "90                 Other                                Working from Home\\n\n",
       "101                Other                                  Working From Home\n",
       "102                Other  Medical appointment in the morning then workin...\n",
       "111                Other           WFH - medical appointment in the morning\n",
       "165                Other                           Work from home in the AM\n",
       "233                Other                                        WFH - India\n",
       "309         Annual leave                                                WFH\n",
       "311                Other                            WFH due to flu symptoms\n",
       "328                Other                         WFH due to ongoing illness\n",
       "333                Other                         As per Teams message (wfh)\n",
       "354  Medical appointment                                Working from Home\\n\n",
       "406                Other                                                wfh\n",
       "408                Other                                            WFH day\n",
       "409                Other  wfh - need to be home due to contractors comin...\n",
       "426                Other                           wfh - due to feeling ill\n",
       "552                Other                     WFH- Boiler Safety certificate\n",
       "573                Other  DR- WFH post-surgery as discussed with ES and ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "type_col = \"Absence type\"\n",
    "desc_col = \"Absence description\"\n",
    "\n",
    "# Detect WFH mentions directly from description (recreated on the fly)\n",
    "wfh_pattern = r\"(?:\\b)(?:wfh|work\\s*from\\s*home|working\\s*from\\s*home|remote|working\\s*remotely|home\\s*working|homeworking|telework|teleworking|hybrid)(?:\\b)\"\n",
    "\n",
    "desc_norm = (\n",
    "    df[desc_col].fillna(\"\")\n",
    "      .astype(str)\n",
    "      .str.lower()\n",
    "      .str.replace(r\"[\\-/_,;:()\\[\\]{}|]+\", \" \", regex=True)\n",
    "      .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "      .str.strip()\n",
    ")\n",
    "\n",
    "df[\"WFH_Mentioned\"] = desc_norm.str.contains(wfh_pattern, regex=True)\n",
    "\n",
    "# Confusion: current Absence type vs whether WFH is mentioned in description\n",
    "confusion = pd.crosstab(\n",
    "    df[type_col].fillna(\"Missing\"),\n",
    "    df[\"WFH_Mentioned\"],\n",
    "    rownames=[type_col],\n",
    "    colnames=[\"WFH mentioned in description\"],\n",
    "    dropna=False\n",
    ")\n",
    "display(confusion)\n",
    "\n",
    "# Show examples where Absence type is NOT WFH but description mentions WFH\n",
    "display(\n",
    "    df.loc[(df[type_col] != \"WFH\") & (df[\"WFH_Mentioned\"]), [type_col, desc_col]]\n",
    "      .drop_duplicates()\n",
    "      .head(50)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1bb34de0-8b08-4ccb-b084-1d10a2650761",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Run WFH detection first  'Is_WFH' not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Safety checks\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mIs_WFH\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df.columns:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mRun WFH detection first  \u001b[39m\u001b[33m'\u001b[39m\u001b[33mIs_WFH\u001b[39m\u001b[33m'\u001b[39m\u001b[33m not found.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Clean strings\u001b[39;00m\n\u001b[32m     12\u001b[39m df[type_col] = df[type_col].astype(\u001b[38;5;28mstr\u001b[39m).str.strip()\n",
      "\u001b[31mValueError\u001b[39m: Run WFH detection first  'Is_WFH' not found."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "type_col = \"Absence type\"\n",
    "desc_col = \"Absence description\"\n",
    "\n",
    "# Safety checks\n",
    "if \"Is_WFH\" not in df.columns:\n",
    "    raise ValueError(\"Run WFH detection first  'Is_WFH' not found.\")\n",
    "\n",
    "# Clean strings\n",
    "df[type_col] = df[type_col].astype(str).str.strip()\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Clean absence category\n",
    "# -------------------------------\n",
    "df[\"Absence_Category_Clean\"] = np.select(\n",
    "    [\n",
    "        df[type_col].str.lower().eq(\"annual leave\"),\n",
    "        df[type_col].str.lower().eq(\"other\") & (df[\"Is_WFH\"] == True)\n",
    "    ],\n",
    "    [\n",
    "        \"Annual leave\",\n",
    "        \"WFH\"\n",
    "    ],\n",
    "    default=df[type_col]\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Confusion matrix: Absence type vs WFH mentioned\n",
    "# -------------------------------\n",
    "confusion_wfh = pd.crosstab(\n",
    "    df[type_col].fillna(\"Missing\"),\n",
    "    df[\"Is_WFH\"],\n",
    "    rownames=[\"Absence type\"],\n",
    "    colnames=[\"WFH mentioned\"],\n",
    "    dropna=False\n",
    ")\n",
    "\n",
    "display(confusion_wfh)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Confusion matrix: Absence type vs Clean category\n",
    "# -------------------------------\n",
    "confusion_clean = pd.crosstab(\n",
    "    df[type_col].fillna(\"Missing\"),\n",
    "    df[\"Absence_Category_Clean\"].fillna(\"Missing\"),\n",
    "    rownames=[\"Absence type\"],\n",
    "    colnames=[\"Absence_Category_Clean\"],\n",
    "    dropna=False\n",
    ")\n",
    "\n",
    "display(confusion_clean)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Sanity checks\n",
    "# -------------------------------\n",
    "print(\"Clean category counts:\")\n",
    "display(df[\"Absence_Category_Clean\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"Rows classified as WFH:\")\n",
    "display(\n",
    "    df.loc[df[\"Absence_Category_Clean\"] == \"WFH\", [type_col, desc_col]]\n",
    "      .drop_duplicates()\n",
    "      .head(30)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cec97f80-5c3d-4294-80ea-4780a1c84946",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Absence_Category_Clean'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Absence_Category_Clean'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Focus on rows still classified as \"Other\" and not WFH\u001b[39;00m\n\u001b[32m      2\u001b[39m others_non_wfh = df.loc[\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAbsence_Category_Clean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.str.lower() == \u001b[33m\"\u001b[39m\u001b[33mother\u001b[39m\u001b[33m\"\u001b[39m) &\n\u001b[32m      4\u001b[39m     (~df[\u001b[33m\"\u001b[39m\u001b[33mIs_WFH\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAbsence description\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m ]\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Top descriptions people have written\u001b[39;00m\n\u001b[32m      9\u001b[39m display(\n\u001b[32m     10\u001b[39m     others_non_wfh\n\u001b[32m     11\u001b[39m         .value_counts(dropna=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     12\u001b[39m         .head(\u001b[32m50\u001b[39m)\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Absence_Category_Clean'"
     ]
    }
   ],
   "source": [
    "# Focus on rows still classified as \"Other\" and not WFH\n",
    "others_non_wfh = df.loc[\n",
    "    (df[\"Absence_Category_Clean\"].str.lower() == \"other\") &\n",
    "    (~df[\"Is_WFH\"]),\n",
    "    \"Absence description\"\n",
    "]\n",
    "\n",
    "# Top descriptions people have written\n",
    "display(\n",
    "    others_non_wfh\n",
    "        .value_counts(dropna=False)\n",
    "        .head(50)\n",
    ")\n",
    "\n",
    "# Optional: sample raw text to manually inspect language\n",
    "display(\n",
    "    others_non_wfh\n",
    "        .dropna()\n",
    "        .sample(min(30, others_non_wfh.dropna().shape[0]), random_state=42)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45be37ad-9804-4fa9-9865-c23efbcfaefd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Is_WFH'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Is_WFH'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      2\u001b[39m extra_wfh_keywords = [\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mworking from home\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mworking remotely\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mremote day\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m ]\n\u001b[32m     10\u001b[39m extra_pattern = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(?:^|[^a-z0-9])(?:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m)(?:$|[^a-z0-9])\u001b[39m\u001b[33m\"\u001b[39m % \u001b[33m\"\u001b[39m\u001b[33m|\u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m     11\u001b[39m     re.escape(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m extra_wfh_keywords\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mIs_WFH\u001b[39m\u001b[33m\"\u001b[39m] = (\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mIs_WFH\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m |\n\u001b[32m     16\u001b[39m     desc_norm.str.contains(extra_pattern, regex=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Re-apply clean category rule\u001b[39;00m\n\u001b[32m     20\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mAbsence_Category_Clean\u001b[39m\u001b[33m\"\u001b[39m] = np.select(\n\u001b[32m     21\u001b[39m     [\n\u001b[32m     22\u001b[39m         df[\u001b[33m\"\u001b[39m\u001b[33mAbsence type\u001b[39m\u001b[33m\"\u001b[39m].str.lower().eq(\u001b[33m\"\u001b[39m\u001b[33mannual leave\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     default=df[\u001b[33m\"\u001b[39m\u001b[33mAbsence type\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     30\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Is_WFH'"
     ]
    }
   ],
   "source": [
    "# Expand WFH keywords to catch remaining variants\n",
    "extra_wfh_keywords = [\n",
    "    \"working from home\",\n",
    "    \"working remotely\",\n",
    "    \"work remotely\",\n",
    "    \"remote from\",\n",
    "    \"remote day\"\n",
    "]\n",
    "\n",
    "extra_pattern = r\"(?:^|[^a-z0-9])(?:%s)(?:$|[^a-z0-9])\" % \"|\".join(\n",
    "    re.escape(k) for k in extra_wfh_keywords\n",
    ")\n",
    "\n",
    "df[\"Is_WFH\"] = (\n",
    "    df[\"Is_WFH\"] |\n",
    "    desc_norm.str.contains(extra_pattern, regex=True)\n",
    ")\n",
    "\n",
    "# Re-apply clean category rule\n",
    "df[\"Absence_Category_Clean\"] = np.select(\n",
    "    [\n",
    "        df[\"Absence type\"].str.lower().eq(\"annual leave\"),\n",
    "        df[\"Absence type\"].str.lower().eq(\"other\") & df[\"Is_WFH\"]\n",
    "    ],\n",
    "    [\n",
    "        \"Annual leave\",\n",
    "        \"WFH\"\n",
    "    ],\n",
    "    default=df[\"Absence type\"]\n",
    ")\n",
    "\n",
    "# Check remaining \"Other\"\n",
    "display(\n",
    "    df.loc[df[\"Absence_Category_Clean\"] == \"Other\", \"Absence description\"]\n",
    "      .value_counts()\n",
    "      .head(30)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b56feb5-c2cb-429a-b1e1-442d7fb1239f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First name</th>\n",
       "      <th>Last name</th>\n",
       "      <th>Team names</th>\n",
       "      <th>Leave entitlement</th>\n",
       "      <th>Absence type</th>\n",
       "      <th>Absence duration total in days</th>\n",
       "      <th>Absence duration for period in days</th>\n",
       "      <th>Absence description</th>\n",
       "      <th>Absence start date</th>\n",
       "      <th>Absence end date</th>\n",
       "      <th>Organisation</th>\n",
       "      <th>Suborganisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pre-agreed WFH days</td>\n",
       "      <td>7/18/2025 0:00</td>\n",
       "      <td>7/23/2025 0:00</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WFH</td>\n",
       "      <td>9/12/2025 0:00</td>\n",
       "      <td>9/12/2025 0:00</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Sickness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/10/2025 0:00</td>\n",
       "      <td>4/10/2025 0:00</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WFH</td>\n",
       "      <td>11/21/2025 0:00</td>\n",
       "      <td>11/21/2025 0:00</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Lenehan</td>\n",
       "      <td>HR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/15/2025 0:00</td>\n",
       "      <td>1/15/2025 0:00</td>\n",
       "      <td>AG</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First name Last name Team names  Leave entitlement Absence type  \\\n",
       "0   Stefanie   Lenehan         HR               20.0        Other   \n",
       "1   Stefanie   Lenehan         HR               20.0        Other   \n",
       "2   Stefanie   Lenehan         HR               20.0     Sickness   \n",
       "3   Stefanie   Lenehan         HR               20.0        Other   \n",
       "4   Stefanie   Lenehan         HR               20.0        Other   \n",
       "\n",
       "   Absence duration total in days  Absence duration for period in days  \\\n",
       "0                             4.0                                  4.0   \n",
       "1                             1.0                                  1.0   \n",
       "2                             1.0                                  1.0   \n",
       "3                             1.0                                  1.0   \n",
       "4                             1.0                                  1.0   \n",
       "\n",
       "    Absence description Absence start date Absence end date Organisation  \\\n",
       "0  Pre-agreed WFH days      7/18/2025 0:00   7/23/2025 0:00           AG   \n",
       "1                   WFH     9/12/2025 0:00   9/12/2025 0:00           AG   \n",
       "2                   NaN     4/10/2025 0:00   4/10/2025 0:00           AG   \n",
       "3                   WFH    11/21/2025 0:00  11/21/2025 0:00           AG   \n",
       "4                   NaN     1/15/2025 0:00   1/15/2025 0:00           AG   \n",
       "\n",
       "  Suborganisation  \n",
       "0              EG  \n",
       "1              EG  \n",
       "2              EG  \n",
       "3              EG  \n",
       "4              EG  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5d9e3c6-b4bc-41b2-97ef-a422cc5ee587",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Absence_Category_Clean'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Absence_Category_Clean'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 1) Replace Absence type with Absence_Category_Clean\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mAbsence type\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAbsence_Category_Clean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 2) Drop WFH-related helper columns\u001b[39;00m\n\u001b[32m      5\u001b[39m df = df.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mIs_WFH\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mWFH_Mentioned_On_Leave\u001b[39m\u001b[33m\"\u001b[39m], errors=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Absence_Category_Clean'"
     ]
    }
   ],
   "source": [
    "# 1) Replace Absence type with Absence_Category_Clean\n",
    "df[\"Absence type\"] = df[\"Absence_Category_Clean\"]\n",
    "\n",
    "# 2) Drop WFH-related helper columns\n",
    "df = df.drop(columns=[\"Is_WFH\", \"WFH_Mentioned_On_Leave\"], errors=\"ignore\")\n",
    "\n",
    "# 3) (Optional) Drop the helper clean column if no longer needed\n",
    "df = df.drop(columns=[\"Absence_Category_Clean\"], errors=\"ignore\")\n",
    "\n",
    "# 4) Verify final columns\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91fc6c21-bd52-4916-afed-9dd8762dadc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Unique Absence type values\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdf\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mAbsence type\u001b[39m\u001b[33m\"\u001b[39m].dropna().unique()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Unique Absence type values\n",
    "df[\"Absence type\"].dropna().unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2707f24-7aeb-40b7-938b-d66728edf1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_sheet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89fc30ab-08a0-42c9-8b86-bab13bfef935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: AbsenseReport_Cleaned_Final.csv\n",
      "Rows: 1670\n",
      "Final Absence types: ['Annual', 'Medical', 'Others', 'Work from home']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "End-to-end Absence Data Cleaning Pipeline (Final)\n",
    "\n",
    "Final absence categories:\n",
    "- Annual\n",
    "- Medical\n",
    "- Work from home\n",
    "- Travel\n",
    "- Others\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "INPUT_PATH = \"AbsenseReportRaw.csv\"\n",
    "OUTPUT_PATH = \"AbsenseReport_Cleaned_Final.csv\"\n",
    "\n",
    "TEAM_COL = \"Team names\"\n",
    "TYPE_COL = \"Absence type\"\n",
    "DESC_COL = \"Absence description\"\n",
    "\n",
    "COLS_TO_DROP = [\n",
    "    \"Status reason\",\n",
    "    \"Absence status\",\n",
    "    \"Is ongoing\",\n",
    "    \"Fit note required\",\n",
    "    \"Estimated return date\",\n",
    "    \"Sickness start date type\",\n",
    "    \"Sickness end date type\",\n",
    "    \"Toil notes\",\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# HELPERS\n",
    "# -------------------------\n",
    "def normalise_text(series: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        series.fillna(\"\")\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .str.replace(r\"[\\-/_,;:()\\[\\]{}|]+\", \" \", regex=True)\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "def build_pattern(keywords):\n",
    "    return r\"(?:^|[^a-z0-9])(?:%s)(?:$|[^a-z0-9])\" % \"|\".join(\n",
    "        re.escape(k) for k in keywords\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# PIPELINE\n",
    "# -------------------------\n",
    "def main():\n",
    "    # 1. Load\n",
    "    df = pd.read_csv(INPUT_PATH)\n",
    "\n",
    "    # 2. Drop unwanted columns\n",
    "    df = df.drop(columns=COLS_TO_DROP, errors=\"ignore\")\n",
    "\n",
    "    # 3. Clean team names + add org columns\n",
    "    df[TEAM_COL] = df[TEAM_COL].astype(str).str.strip().replace({\"nan\": np.nan})\n",
    "    df[\"Organisation\"] = None\n",
    "    df[\"Suborganisation\"] = None\n",
    "\n",
    "    # 4. Map Organisation / Suborganisation\n",
    "    teams_eg = {\"HR\", \"UK BDM\", \"DE BDM\", \"Engineering\", \"Operations\", \"Investment\", \"Investments\"}\n",
    "    teams_ag = {\"Agri\", \"AG Legal\", \"Group Legal\"}\n",
    "    teams_ug = {\"Executive\", \"UG Business Support\", \"Group Finance\", \"Property\"}\n",
    "\n",
    "    df.loc[df[TEAM_COL].isin(teams_eg), [\"Organisation\", \"Suborganisation\"]] = [\"AG\", \"EG\"]\n",
    "    df.loc[df[TEAM_COL].isin(teams_ag), [\"Organisation\", \"Suborganisation\"]] = [\"AG\", \"AG\"]\n",
    "    df.loc[df[TEAM_COL].isin(teams_ug), [\"Organisation\", \"Suborganisation\"]] = [\"UG\", \"UG\"]\n",
    "\n",
    "    # 5. Robust WFH detection\n",
    "    type_norm = normalise_text(df[TYPE_COL])\n",
    "    desc_norm = normalise_text(df[DESC_COL])\n",
    "\n",
    "    wfh_keywords = [\n",
    "        \"wfh\", \"work from home\", \"working from home\",\n",
    "        \"workfromhome\", \"remote\", \"working remotely\",\n",
    "        \"home working\", \"telework\", \"hybrid\"\n",
    "    ]\n",
    "    wfh_pattern = build_pattern(wfh_keywords)\n",
    "\n",
    "    df[\"Is_WFH\"] = (\n",
    "        type_norm.str.contains(wfh_pattern, regex=True) |\n",
    "        desc_norm.str.contains(wfh_pattern, regex=True)\n",
    "    )\n",
    "\n",
    "    # 6. Clean Absence Category (WFH logic)\n",
    "    df[\"Absence_Category_Clean\"] = np.select(\n",
    "        [\n",
    "            type_norm.eq(\"annual leave\"),\n",
    "            type_norm.eq(\"other\") & df[\"Is_WFH\"]\n",
    "        ],\n",
    "        [\n",
    "            \"Annual leave\",\n",
    "            \"WFH\"\n",
    "        ],\n",
    "        default=df[TYPE_COL]\n",
    "    )\n",
    "\n",
    "    # 7. Final 5-category consolidation\n",
    "    final_category_map = {\n",
    "        \"Annual leave\": \"Annual\",\n",
    "        \"Maternity leave\": \"Annual\",\n",
    "        \"Bereavement leave\": \"Annual\",\n",
    "        \"Compassionate leave\": \"Annual\",\n",
    "\n",
    "        \"Medical appointment\": \"Medical\",\n",
    "        \"Dental appointment\": \"Medical\",\n",
    "        \"Sickness\": \"Medical\",\n",
    "\n",
    "        \"WFH\": \"Work from home\",\n",
    "\n",
    "        \"Training / events\": \"Others\",\n",
    "        \"Other\": \"Others\"\n",
    "    }\n",
    "\n",
    "    df[\"Absence Category Final\"] = (\n",
    "        df[\"Absence_Category_Clean\"]\n",
    "        .map(final_category_map)\n",
    "        .fillna(\"Others\")\n",
    "    )\n",
    "\n",
    "    # 8. Replace Absence type + drop helper columns\n",
    "    df[TYPE_COL] = df[\"Absence Category Final\"]\n",
    "\n",
    "    df = df.drop(\n",
    "        columns=[\"Is_WFH\", \"Absence_Category_Clean\", \"Absence Category Final\"],\n",
    "        errors=\"ignore\"\n",
    "    )\n",
    "    \n",
    "    # \n",
    "    \n",
    "    from ftfy import fix_text\n",
    "    \n",
    "    \n",
    "    def fix_encoding(text):\n",
    "        if isinstance(text, str):\n",
    "            return fix_text(text)\n",
    "        return text\n",
    "    \n",
    "    # Apply to name columns\n",
    "    df[\"First name\"] = df[\"First name\"].apply(fix_encoding)\n",
    "    df[\"Last name\"] = df[\"Last name\"].apply(fix_encoding)\n",
    "\n",
    "\n",
    "    # 9. Save output\n",
    "    df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "    # 10. Console audit\n",
    "    print(\"Saved:\", OUTPUT_PATH)\n",
    "    print(\"Rows:\", len(df))\n",
    "    print(\"Final Absence types:\", sorted(df[TYPE_COL].unique()))\n",
    "\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb5af06-f4bd-4f6d-a5cb-be0bed22b09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: AbsenseReport_Cleaned_Final.csv\n",
      "Raw rows: 1670\n",
      "Raw exact duplicates: 747\n",
      "Rows before dedupe (post-processing): 1670\n",
      "Exact duplicates removed (post-processing): 747\n",
      "Final rows: 923\n",
      "Final Absence types: ['Annual', 'Medical', 'Others', 'Work from home']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "End-to-end Absence Data Cleaning Pipeline (Final + De-duplication)\n",
    "\n",
    "Final absence categories:\n",
    "- Annual\n",
    "- Medical\n",
    "- Work from home\n",
    "- Travel\n",
    "- Others\n",
    "\n",
    "Whats added vs your version:\n",
    "- Removes exact duplicate rows (safe dedupe) + prints audit counts\n",
    "- Optional business-key dedupe scaffold (commented)\n",
    "- ftfy name-fix is now safe (works even if ftfy or name columns are missing)\n",
    "\n",
    "Latest edit:\n",
    "- Removed non-existent \"AG Legal\"\n",
    "- Ensured \"Group Legal\" is mapped under UG (United Green)\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "INPUT_PATH = \"AbsenseReportRaw.csv\"\n",
    "OUTPUT_PATH = \"AbsenseReport_Cleaned_Final.csv\"\n",
    "\n",
    "TEAM_COL = \"Team names\"\n",
    "TYPE_COL = \"Absence type\"\n",
    "DESC_COL = \"Absence description\"\n",
    "\n",
    "COLS_TO_DROP = [\n",
    "    \"Status reason\",\n",
    "    \"Absence status\",\n",
    "    \"Is ongoing\",\n",
    "    \"Fit note required\",\n",
    "    \"Estimated return date\",\n",
    "    \"Sickness start date type\",\n",
    "    \"Sickness end date type\",\n",
    "    \"Toil notes\",\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# HELPERS\n",
    "# -------------------------\n",
    "def normalise_text(series: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        series.fillna(\"\")\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .str.replace(r\"[\\-/_,;:()\\[\\]{}|]+\", \" \", regex=True)\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "def build_pattern(keywords):\n",
    "    return r\"(?:^|[^a-z0-9])(?:%s)(?:$|[^a-z0-9])\" % \"|\".join(\n",
    "        re.escape(k) for k in keywords\n",
    "    )\n",
    "\n",
    "def safe_fix_text_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Attempts to fix mojibake/encoding issues using ftfy if available.\n",
    "    If ftfy isn't installed, returns the original series unchanged.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from ftfy import fix_text\n",
    "    except Exception:\n",
    "        return s\n",
    "\n",
    "    def _fix(x):\n",
    "        return fix_text(x) if isinstance(x, str) else x\n",
    "\n",
    "    return s.apply(_fix)\n",
    "\n",
    "# -------------------------\n",
    "# PIPELINE\n",
    "# -------------------------\n",
    "def main():\n",
    "    # 1) Load\n",
    "    df = pd.read_csv(INPUT_PATH)\n",
    "\n",
    "    # --- audit: duplicates in raw\n",
    "    raw_rows = len(df)\n",
    "    raw_dup_exact = int(df.duplicated().sum())\n",
    "\n",
    "    # 2) Drop unwanted columns\n",
    "    df = df.drop(columns=COLS_TO_DROP, errors=\"ignore\")\n",
    "\n",
    "    # 3) Clean team names + add org columns\n",
    "    if TEAM_COL not in df.columns:\n",
    "        raise KeyError(f\"Missing required column: '{TEAM_COL}'\")\n",
    "\n",
    "    df[TEAM_COL] = df[TEAM_COL].astype(str).str.strip().replace({\"nan\": np.nan})\n",
    "    df[\"Organisation\"] = None\n",
    "    df[\"Suborganisation\"] = None\n",
    "\n",
    "    # 4) Map Organisation / Suborganisation\n",
    "    # Notes:\n",
    "    # - \"AG Legal\" does not exist and is removed\n",
    "    # - \"Group Legal\" is mapped to UG (United Green)\n",
    "    teams_eg = {\"HR\", \"UK BDM\", \"DE BDM\", \"Engineering\", \"Operations\", \"Investment\", \"Investments\"}\n",
    "    teams_ag = {\"Agri\"}  # No \"AG Legal\" in the data\n",
    "    teams_ug = {\"Executive\", \"UG Business Support\", \"Group Finance\", \"Property\", \"Group Legal\"}\n",
    "\n",
    "    df.loc[df[TEAM_COL].isin(teams_eg), [\"Organisation\", \"Suborganisation\"]] = [\"AG\", \"EG\"]\n",
    "    df.loc[df[TEAM_COL].isin(teams_ag), [\"Organisation\", \"Suborganisation\"]] = [\"AG\", \"AG\"]\n",
    "    df.loc[df[TEAM_COL].isin(teams_ug), [\"Organisation\", \"Suborganisation\"]] = [\"UG\", \"UG\"]\n",
    "\n",
    "    # 5) Robust WFH detection\n",
    "    for col in [TYPE_COL, DESC_COL]:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Missing required column: '{col}'\")\n",
    "\n",
    "    type_norm = normalise_text(df[TYPE_COL])\n",
    "    desc_norm = normalise_text(df[DESC_COL])\n",
    "\n",
    "    wfh_keywords = [\n",
    "        \"wfh\", \"work from home\", \"working from home\",\n",
    "        \"workfromhome\", \"remote\", \"working remotely\",\n",
    "        \"home working\", \"telework\", \"hybrid\"\n",
    "    ]\n",
    "    wfh_pattern = build_pattern(wfh_keywords)\n",
    "\n",
    "    df[\"Is_WFH\"] = (\n",
    "        type_norm.str.contains(wfh_pattern, regex=True) |\n",
    "        desc_norm.str.contains(wfh_pattern, regex=True)\n",
    "    )\n",
    "\n",
    "    # 6) Clean Absence Category (WFH logic)\n",
    "    df[\"Absence_Category_Clean\"] = np.select(\n",
    "        [\n",
    "            type_norm.eq(\"annual leave\"),\n",
    "            type_norm.eq(\"other\") & df[\"Is_WFH\"],\n",
    "        ],\n",
    "        [\n",
    "            \"Annual leave\",\n",
    "            \"WFH\",\n",
    "        ],\n",
    "        default=df[TYPE_COL]\n",
    "    )\n",
    "\n",
    "    # 7) Final 5-category consolidation\n",
    "    final_category_map = {\n",
    "        \"Annual leave\": \"Annual\",\n",
    "        \"Maternity leave\": \"Annual\",\n",
    "        \"Bereavement leave\": \"Annual\",\n",
    "        \"Compassionate leave\": \"Annual\",\n",
    "\n",
    "        \"Medical appointment\": \"Medical\",\n",
    "        \"Dental appointment\": \"Medical\",\n",
    "        \"Sickness\": \"Medical\",\n",
    "\n",
    "        \"WFH\": \"Work from home\",\n",
    "\n",
    "        # Travel mapping: add values here if your raw data includes them\n",
    "        \"Travel\": \"Travel\",\n",
    "\n",
    "        \"Training / events\": \"Others\",\n",
    "        \"Other\": \"Others\",\n",
    "    }\n",
    "\n",
    "    df[\"Absence Category Final\"] = (\n",
    "        df[\"Absence_Category_Clean\"]\n",
    "        .map(final_category_map)\n",
    "        .fillna(\"Others\")\n",
    "    )\n",
    "\n",
    "    # 8) Replace Absence type + drop helper columns\n",
    "    df[TYPE_COL] = df[\"Absence Category Final\"]\n",
    "\n",
    "    df = df.drop(\n",
    "        columns=[\"Is_WFH\", \"Absence_Category_Clean\", \"Absence Category Final\"],\n",
    "        errors=\"ignore\"\n",
    "    )\n",
    "\n",
    "    # 9) Fix encoding issues in name columns (safe)\n",
    "    for name_col in [\"First name\", \"Last name\"]:\n",
    "        if name_col in df.columns:\n",
    "            df[name_col] = safe_fix_text_series(df[name_col])\n",
    "\n",
    "    # 10) De-duplicate (SAFE): remove exact duplicates\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates()\n",
    "    after = len(df)\n",
    "    removed = before - after\n",
    "\n",
    "    # OPTIONAL: Business-key dedupe (use only if you confirm these columns reliably define a record)\n",
    "    # dedupe_cols = [c for c in [\n",
    "    #     \"First name\", \"Last name\", TEAM_COL, TYPE_COL,\n",
    "    #     \"Absence start date\", \"Absence end date\", DESC_COL\n",
    "    # ] if c in df.columns]\n",
    "    # if dedupe_cols:\n",
    "    #     df = df.drop_duplicates(subset=dedupe_cols, keep=\"first\")\n",
    "\n",
    "    # 11) Save output\n",
    "    df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "    # 12) Console audit\n",
    "    print(\"Saved:\", OUTPUT_PATH)\n",
    "    print(f\"Raw rows: {raw_rows}\")\n",
    "    print(f\"Raw exact duplicates: {raw_dup_exact}\")\n",
    "    print(f\"Rows before dedupe (post-processing): {before}\")\n",
    "    print(f\"Exact duplicates removed (post-processing): {removed}\")\n",
    "    print(f\"Final rows: {after}\")\n",
    "    print(\"Final Absence types:\", sorted(df[TYPE_COL].dropna().unique()))\n",
    "\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4098cc73-bcad-4ba5-9545-c33c47bad3af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
